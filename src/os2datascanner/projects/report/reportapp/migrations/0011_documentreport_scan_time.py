# Generated by Django 2.2.10 on 2020-10-14 14:26

from django.db import migrations, models

from os2datascanner.engine2.pipeline import messages


def extract_timestamps(apps, schema_editor):
    """Updating data in a large DocumentReport table is necessary to do in batches.
    If Out of memory still occurs try reducing batch size."""

    DocumentReport = apps.get_model("os2datascanner_report", "DocumentReport")
    document_reports_count = DocumentReport.objects.filter(data__scan_tag__isnull=False).count()
    batchsize = 10000
    i = 0
    while i < document_reports_count:
        print('i: {}'.format(str(i)))
        batch = DocumentReport.objects.filter(data__scan_tag__isnull=False)[i:batchsize+i]
        i += batchsize
        for dr in batch:
            scan_tag = messages.ScanSpecFragment.from_json_object(dr.data["scan_tag"])
            if scan_tag.time:
                dr.scan_time = scan_tag.time
        DocumentReport.objects.bulk_update(batch, ['scan_time'])


class Migration(migrations.Migration):

    dependencies = [
        ('os2datascanner_report', '0010_inaction_handling'),
    ]

    operations = [
        migrations.AddField(
            model_name='documentreport',
            name='scan_time',
            field=models.DateTimeField(null=True),
        ),
        migrations.RunPython(extract_timestamps,
                reverse_code=migrations.RunPython.noop)
    ]
